#user  nobody;
worker_processes  1;

#error_log  logs/error.log;
error_log  logs/error.log  debug;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid;


events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

    ssl on;
    ssl_certificate           /etc/nginx/ssl/cert.pem;
    ssl_certificate_key       /etc/nginx/ssl/key.pem;

    ssl_protocols  TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers HIGH:!aNULL:!eNULL:!EXPORT:!CAMELLIA:!DES:!MD5:!PSK:!RC4;

    ssl_prefer_server_ciphers on;
    ssl_session_cache  builtin:1000  shared:SSL:10m;

    include /etc/nginx/conf.d/*.conf;

    lua_package_path "/opt/lua/lua-resty-uuid/lib/?.lua;/opt/lua/lua-resty-kafka/lib/?.lua;;";

    # because we want to capture the request payload, we need to set lua_need_request_body to on.
    # Refer: https://github.com/openresty/lua-nginx-module#lua_need_request_body
    lua_need_request_body on;

    server {
        listen 443;

        location / {
            # the following is required so that nginx can resolve to the dependent containers.
            # remove if not using docker-compose
            resolver 127.0.0.11;
            proxy_pass http://tomcat:8080;

            set $resp_body "";

            # buffer the upstream response and capture it in a context variable
            # ngx.arg[2] will be truth-y if we're at the end of the proxied response
            body_filter_by_lua_block {
                local resp_body = ngx.arg[1]
                ngx.ctx.buffered = (ngx.ctx.buffered or "") .. resp_body

                if ngx.arg[2] then
                    ngx.var.resp_body = ngx.ctx.buffered
                end
            }

            # during the log phase, send the content to kafka
            # since cosockets aren't available in this phase (context), we need to delegate
            # the kafka call to a context that does have access to creating socket connections
            log_by_lua_block {
                local function handler(premature, req, res)
                    if premature then
                        return
                    end

                    local cjson = require "cjson"
                    local client = require "resty.kafka.client"
                    local producer = require "resty.kafka.producer"
                    local uuid = require "resty.uuid"

                    local topic_name = "test"

                    local broker_list = {
                        { host = "kafka", port = 9092 },
                    }

                    local bp = producer:new(broker_list, { producer_type = "async", refresh_interval = 5000 })

                    local payload = cjson.encode({ request = req or {}, response = res or {} })
                    -- ngx.log(ngx.DEBUG, "Sending request ", payload)

                    local ok, err = bp:send("test", uuid:generate(), payload)

                    if not ok then
                        ngx.log(ngx.ERR, "Unable to pipe payloads to kafka ", err)
                    end
                end

                local ok, err = ngx.timer.at(0, handler, ngx.var.request_body, ngx.var.resp_body)
                if not ok then
                    ngx.log(ngx.ERR, "failed to create timer: ", err)
                    return
                end
            }
        }
    }
}
